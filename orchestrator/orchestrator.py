"""
Orchestrator Agent - Orchestration des workflows et sprints
G√®re l'ex√©cution des pipelines et le d√©veloppement par sprints
Version: 2.0.0
"""

import os
import sys
import yaml
import asyncio
import json
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
from collections import defaultdict
import traceback

# Ajouter le chemin pour l'import de BaseAgent
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from agents.base_agent.base_agent import BaseAgent, AgentStatus
except ImportError:
    # Fallback pour les tests
    class AgentStatus(Enum):
        CREATED = "created"
        INITIALIZING = "initializing"
        READY = "ready"
        ERROR = "error"
    
    class BaseAgent:
        def __init__(self, config_path: str = ""):
            self.config_path = config_path
            self._logger = print
            self._name = "orchestrator"
            self._status = AgentStatus.CREATED
            self.config = {}
            self._start_time = datetime.now()
        
        async def initialize(self) -> bool:
            self._status = AgentStatus.READY
            return True
        
        @property
        def uptime(self):
            return datetime.now() - self._start_time


# =====================================================================
# √âNUM√âRATIONS
# =====================================================================

class WorkflowStatus(Enum):
    """Statuts d'un workflow"""
    PENDING = "pending"
    PLANNING = "planning"
    READY = "ready"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class StepStatus(Enum):
    """Statuts d'une √©tape"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"
    BLOCKED = "blocked"


class DomainType(Enum):
    """Types de domaines support√©s"""
    SMART_CONTRACT = "smart_contract"
    BACKEND = "backend"
    FRONTEND = "frontend"
    DATABASE = "database"
    DEVOPS = "devops"
    MONITORING = "monitoring"
    DOCUMENTATION = "documentation"


class FragmentStatus(Enum):
    """Statuts d'un fragment"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    VALIDATED = "validated"
    FAILED = "failed"
    BLOCKED = "blocked"


# =====================================================================
# CLASSES DE BASE
# =====================================================================

class WorkflowStep:
    """√âtape d'un workflow"""
    
    def __init__(self, 
                 name: str,
                 agent_type: str,
                 task_type: str,
                 parameters: Dict[str, Any] = None,
                 depends_on: List[str] = None,
                 timeout: int = 300,
                 retry_count: int = 0,
                 max_retries: int = 3):
        
        self.id = f"step_{datetime.now().timestamp()}_{name}"
        self.name = name
        self.agent_type = agent_type
        self.task_type = task_type
        self.parameters = parameters or {}
        self.depends_on = depends_on or []
        self.timeout = timeout
        self.retry_count = retry_count
        self.max_retries = max_retries
        self.status = StepStatus.PENDING
        self.result = None
        self.error = None
        self.started_at = None
        self.completed_at = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "name": self.name,
            "agent_type": self.agent_type,
            "task_type": self.task_type,
            "parameters": self.parameters,
            "depends_on": self.depends_on,
            "status": self.status.value,
            "retry_count": self.retry_count,
            "max_retries": self.max_retries
        }


class Workflow:
    """Workflow complet"""
    
    def __init__(self, name: str, workflow_type: str = "standard"):
        self.id = f"workflow_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        self.name = name
        self.workflow_type = workflow_type
        self.status = WorkflowStatus.PENDING
        self.steps: List[WorkflowStep] = []
        self.created_at = datetime.now()
        self.started_at = None
        self.completed_at = None
        self.context: Dict[str, Any] = {}
        self.results: Dict[str, Any] = {}
        self.artifacts: List[str] = []
        self.report_path = None
    
    def add_step(self, step: WorkflowStep):
        """Ajoute une √©tape au workflow"""
        self.steps.append(step)
    
    def get_step(self, step_name: str) -> Optional[WorkflowStep]:
        """R√©cup√®re une √©tape par son nom"""
        for step in self.steps:
            if step.name == step_name:
                return step
        return None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "name": self.name,
            "type": self.workflow_type,
            "status": self.status.value,
            "steps": [s.to_dict() for s in self.steps],
            "created_at": self.created_at.isoformat(),
            "started_at": self.started_at.isoformat() if self.started_at else None,
            "completed_at": self.completed_at.isoformat() if self.completed_at else None
        }


# =====================================================================
# SPRINT MANAGER
# =====================================================================

class SprintManager:
    """
    Gestionnaire de sprints multi-domaines
    Coordonne le d√©veloppement parall√®le sur tous les aspects du projet
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.current_sprint = None
        self.fragments: Dict[str, Dict] = {}
        self.dependency_graph: Dict[str, List[str]] = {}
        self.results: Dict[str, Any] = {}
        self.logger = print  # Sera remplac√© par l'orchestrateur
        
        self.metrics = {
            "sprints_completed": 0,
            "fragments_total": 0,
            "fragments_completed": 0,
            "fragments_failed": 0,
            "iterations_total": 0,
            "avg_iterations_per_fragment": 0.0,
            "success_rate": 0.0,
            
            # M√©triques par domaine
            "by_domain": {
                "smart_contract": {"total": 0, "completed": 0, "failed": 0},
                "backend": {"total": 0, "completed": 0, "failed": 0},
                "frontend": {"total": 0, "completed": 0, "failed": 0},
                "database": {"total": 0, "completed": 0, "failed": 0},
                "devops": {"total": 0, "completed": 0, "failed": 0},
                "monitoring": {"total": 0, "completed": 0, "failed": 0},
                "documentation": {"total": 0, "completed": 0, "failed": 0}
            }
        }
    
    def set_logger(self, logger):
        """D√©finit le logger"""
        self.logger = logger
    
    def load_specs(self, spec_file: str) -> Dict[str, Any]:
        """Charge les sp√©cifications depuis un fichier JSON"""
        self.logger(f"üìã Chargement des sp√©cifications: {spec_file}")
        
        try:
            with open(spec_file, 'r', encoding='utf-8') as f:
                specs = json.load(f)
        except FileNotFoundError:
            self.logger(f"‚ùå Fichier non trouv√©: {spec_file}")
            # Retourner des sp√©cifications par d√©faut pour les tests
            specs = self._get_default_specs()
        except Exception as e:
            self.logger(f"‚ùå Erreur chargement: {e}")
            specs = self._get_default_specs()
        
        # Indexer les fragments par ID
        for fragment in specs.get("fragments", []):
            self.fragments[fragment["id"]] = fragment
            self.metrics["fragments_total"] += 1
            
            # Statistiques par domaine
            domain = fragment.get("domain", "unknown")
            if domain in self.metrics["by_domain"]:
                self.metrics["by_domain"][domain]["total"] += 1
        
        # Construire le graphe de d√©pendances
        for dep in specs.get("dependencies", []):
            from_id = dep["from"]
            to_id = dep["to"]
            
            if from_id not in self.dependency_graph:
                self.dependency_graph[from_id] = []
            self.dependency_graph[from_id].append(to_id)
        
        self.current_sprint = {
            "id": specs.get("sprint", "SPRINT-000"),
            "name": specs.get("name", "Sans nom"),
            "strategy": specs.get("strategy", "largeur_dabord"),
            "fragments": list(self.fragments.keys()),
            "dependencies": self.dependency_graph,
            "specs": specs
        }
        
        return specs
    
    def _get_default_specs(self) -> Dict[str, Any]:
        """Retourne des sp√©cifications par d√©faut pour les tests"""
        return {
            "sprint": "SPRINT-001",
            "name": "Sprint de test",
            "strategy": "largeur_dabord",
            "fragments": [
                {
                    "id": "TEST_001",
                    "domain": "smart_contract",
                    "name": "Fragment test",
                    "language": "solidity",
                    "complexity": 2
                }
            ],
            "dependencies": []
        }
    
    def plan_sprint(self) -> List[Dict]:
        """Planifie l'ordre d'ex√©cution des fragments"""
        if not self.current_sprint:
            return []
        
        strategy = self.current_sprint["strategy"]
        
        if strategy == "largeur_dabord":
            return self._plan_largeur()
        elif strategy == "profondeur_dabord":
            return self._plan_profondeur()
        else:
            return self._resolve_dependencies()
    
    def _plan_largeur(self) -> List[Dict]:
        """Planification en largeur : tous les domaines en parall√®le"""
        fragments_by_domain = defaultdict(list)
        
        for fragment_id, fragment in self.fragments.items():
            domain = fragment.get("domain", "unknown")
            fragments_by_domain[domain].append(fragment)
        
        # Trier par complexit√© au sein de chaque domaine
        for domain in fragments_by_domain:
            fragments_by_domain[domain].sort(
                key=lambda x: x.get("complexity", 5)
            )
        
        # Entrelacer les fragments simples de tous les domaines
        plan = []
        max_len = max((len(f) for f in fragments_by_domain.values()), default=0)
        
        for i in range(max_len):
            for domain in fragments_by_domain:
                if i < len(fragments_by_domain[domain]):
                    plan.append(fragments_by_domain[domain][i])
        
        return plan
    
    def _plan_profondeur(self) -> List[Dict]:
        """Planification en profondeur : domaine par domaine"""
        # Priorit√© : smart_contract ‚Üí backend ‚Üí frontend ‚Üí database ‚Üí devops
        priority = ["smart_contract", "backend", "frontend", "database", "devops", "monitoring", "documentation"]
        
        plan = []
        for domain in priority:
            domain_fragments = [
                f for f in self.fragments.values()
                if f.get("domain") == domain
            ]
            domain_fragments.sort(key=lambda x: x.get("complexity", 5))
            plan.extend(domain_fragments)
        
        return plan
    
    def _resolve_dependencies(self) -> List[Dict]:
        """R√©sout le graphe de d√©pendances (tri topologique)"""
        visited = set()
        order = []
        
        def dfs(fragment_id):
            if fragment_id in visited:
                return
            visited.add(fragment_id)
            
            for dep in self.dependency_graph.get(fragment_id, []):
                dfs(dep)
            
            if fragment_id in self.fragments:
                order.append(self.fragments[fragment_id])
        
        for fragment_id in self.fragments:
            if fragment_id not in visited:
                dfs(fragment_id)
        
        return order


# =====================================================================
# ORCHESTRATOR AGENT
# =====================================================================

class OrchestratorAgent(BaseAgent):
    """
    Agent orchestrateur principal
    G√®re l'ex√©cution des workflows et des sprints
    """
    
    def __init__(self, config_path: str = ""):
        """Initialise l'orchestrateur"""
        super().__init__(config_path)
        
        self._logger.info("üöÄ Orchestrator Agent cr√©√©")
        
        # Charger la configuration
        self._load_configuration()
        
        # √âtat interne
        self._agents: Dict[str, Any] = {}
        self._workflows: Dict[str, Workflow] = {}
        self._current_workflow: Optional[Workflow] = None
        self._sprint_manager: Optional[SprintManager] = None
        
        # Statistiques
        self._stats = {
            "workflows_executed": 0,
            "workflows_completed": 0,
            "workflows_failed": 0,
            "steps_executed": 0,
            "steps_failed": 0,
            "sprints_completed": 0,
            "start_time": datetime.now()
        }
        
        # Composants
        self._components = {}
    
    def _load_configuration(self):
        """Charge la configuration depuis le fichier YAML"""
        try:
            # Utiliser self._config_path au lieu de self.config_path
            if self._config_path and os.path.exists(self._config_path):
                with open(self._config_path, 'r', encoding='utf-8') as f:
                    file_config = yaml.safe_load(f) or {}
                
                # Stocker dans self._agent_config (pas self.config)
                self._agent_config = file_config
                self._logger.info(f"‚úÖ Configuration charg√©e depuis {self._config_path}")
                
                # Configuration par d√©faut pour les sprints
                if "sprint_config" not in self._agent_config:
                    self._agent_config["sprint_config"] = {
                        "enabled": True,
                        "default_strategy": "largeur_dabord",
                        "max_iterations_per_fragment": 3,
                        "reports_path": "./reports/sprints/"
                    }
            else:
                self._logger.warning("‚ö†Ô∏è Fichier de configuration non trouv√©")
                self._agent_config = {
                    "sprint_config": {
                        "enabled": True,
                        "default_strategy": "largeur_dabord",
                        "max_iterations_per_fragment": 3,
                        "reports_path": "./reports/sprints/"
                    }
                }
        except Exception as e:
            self._logger.error(f"‚ùå Erreur chargement config: {e}")
            self._agent_config = {
                "sprint_config": {
                    "enabled": True,
                    "default_strategy": "largeur_dabord",
                    "max_iterations_per_fragment": 3,
                    "reports_path": "./reports/sprints/"
                }
            }
    
    async def initialize(self) -> bool:
        """Initialisation asynchrone"""
        try:
            self._status = AgentStatus.INITIALIZING
            self._logger.info("Initialisation de l'orchestrateur...")
            
            # Initialiser les composants
            await self._initialize_components()
            
            # Initialiser le sprint manager
            self._sprint_manager = SprintManager(self.config.get("sprint_config", {}))
            self._sprint_manager.set_logger(self._logger.info)
            
            self._status = AgentStatus.READY
            self._logger.info("‚úÖ Orchestrateur pr√™t")
            return True
            
        except Exception as e:
            self._logger.error(f"‚ùå Erreur initialisation: {e}")
            self._logger.error(traceback.format_exc())
            self._status = AgentStatus.ERROR
            return False
    
    async def _initialize_components(self):
        """Initialise les composants"""
        self._logger.info("Initialisation des composants...")
        
        self._components = {
            "workflow_engine": True,
            "sprint_manager": True,
            "agent_registry": False  # Sera activ√© quand le registry sera disponible
        }
        
        self._logger.info(f"‚úÖ Composants: {list(self._components.keys())}")
        return self._components
    
    async def generate_project_spec(self, project_name: str, project_type: str = "defi") -> str:
        """
        G√©n√®re un fichier de sp√©cification complet pour un projet
        
        Args:
            project_name: Nom du projet
            project_type: Type de projet (defi, nft, gaming, dao)
        
        Returns:
            Chemin vers le fichier JSON g√©n√©r√©
        """
        self._logger.info(f"üìã G√©n√©ration de sp√©cification pour projet: {project_name}")
        
        # Template de base selon le type de projet
        templates = {
            "defi": self._get_defi_template,
            "nft": self._get_nft_template,
            "gaming": self._get_gaming_template,
            "dao": self._get_dao_template
        }
        
        template_func = templates.get(project_type, self._get_defi_template)
        spec = template_func(project_name)
        
        # Sauvegarder le fichier
        specs_dir = Path("./specs/projects")
        specs_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"{project_name.lower().replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.json"
        filepath = specs_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(spec, f, indent=2, ensure_ascii=False)
        
        self._logger.info(f"‚úÖ Sp√©cification projet g√©n√©r√©e: {filepath}")
        return str(filepath)

    async def _get_agent(self, agent_name: str) -> Optional[Any]:
        """
        R√©cup√®re une instance d'agent depuis le registry
        
        Args:
            agent_name: Nom de l'agent √† r√©cup√©rer
            
        Returns:
            Instance de l'agent ou None si non disponible
        """
        self._logger.debug(f"üîç Recherche de l'agent: {agent_name}")
        
        try:
            # Essayer d'importer le registry
            from agents.registry.registry_agent import RegistryAgent
            
            # Cr√©er une instance du registry (ou utiliser une instance partag√©e)
            registry = RegistryAgent()
            await registry.initialize()
            
            # R√©cup√©rer l'agent depuis le registry
            agent_info = await registry.get_agent(agent_name)
            
            if agent_info:
                # Importer dynamiquement la classe
                module_path = agent_info.get("module_path", f"agents.{agent_name}.agent")
                class_name = agent_info.get("class_name", f"{agent_name.capitalize()}Agent")
                
                module = __import__(module_path, fromlist=[class_name])
                agent_class = getattr(module, class_name)
                
                # Cr√©er et initialiser l'instance
                agent_instance = agent_class()
                await agent_instance.initialize()
                
                self._logger.info(f"‚úÖ Agent {agent_name} charg√© depuis le registry")
                return agent_instance
                
        except ImportError:
            self._logger.warning(f"‚ö†Ô∏è Registry non disponible, utilisation du mode simulation")
        except Exception as e:
            self._logger.error(f"‚ùå Erreur chargement agent {agent_name}: {e}")
        
        # Mode simulation
        self._logger.warning(f"‚ö†Ô∏è Agent {agent_name} non disponible (simulation)")
        return None

    async def prepare_and_execute_sprint(self, 
                                         project_name: str, 
                                         project_type: str = "defi",
                                         strategy: str = "largeur_dabord") -> Dict[str, Any]:
        """
        Pr√©pare et ex√©cute un sprint complet :
        1. G√©n√®re la spec globale
        2. Appelle architect pour d√©coupage en fragments
        3. Ex√©cute le sprint
        
        Args:
            project_name: Nom du projet
            project_type: Type de projet
            strategy: Strat√©gie de sprint
        
        Returns:
            Rapport complet du sprint
        """
        self._logger.info(f"üöÄ Pr√©paration du sprint pour projet: {project_name}")
        
        # √âtape 1: G√©n√©rer la spec globale
        spec_file = await self.generate_project_spec(project_name, project_type)
        
        # √âtape 2: Appeler l'agent architect pour le d√©coupage
        architect_agent = await self._get_agent("architect")
        if not architect_agent:
            self._logger.warning("‚ö†Ô∏è Agent architect non disponible, utilisation du d√©coupage par d√©faut")
            fragments_info = {"by_domain": {}, "metadata": {"total_fragments": 0}}
        else:
            # Charger la spec
            with open(spec_file, 'r') as f:
                global_spec = json.load(f)
            
            # Demander le d√©coupage
            fragments_info = await architect_agent.split_spec_into_fragments(global_spec, strategy)
        
        # √âtape 3: Ex√©cuter le sprint
        report = await self.execute_sprint(spec_file)
        
        # Ajouter les infos de d√©coupage au rapport
        report["fragments_info"] = {
            "total": fragments_info["metadata"]["total_fragments"],
            "by_domain": {k: len(v) for k, v in fragments_info["by_domain"].items()},
            "estimated_sprints": fragments_info["metadata"].get("estimated_sprints", 1)
        }
        
        return report

    def _get_defi_template(self, project_name: str) -> Dict:
        """Template pour projet DeFi"""
        return {
            "project": project_name,
            "type": "defi",
            "version": "1.0.0",
            "generated_at": datetime.now().isoformat(),
            "description": "Plateforme DeFi compl√®te avec token, staking, et interface web",
            "domains": ["smart_contract", "backend", "frontend", "database", "devops", "documentation"],
            "fragments": [
                {
                    "id": f"{project_name}_SC_001",
                    "domain": "smart_contract",
                    "name": "Token ERC20",
                    "description": "Token standard avec mint/burn",
                    "language": "solidity",
                    "version": "0.8.19",
                    "framework": "foundry",
                    "complexity": 2,
                    "dependencies": ["openzeppelin/contracts@4.9.0"],
                    "specification": {
                        "contract_name": f"{project_name}Token",
                        "symbol": project_name[:5].upper(),
                        "features": ["mint", "burn", "transfer", "approve"]
                    }
                },
                {
                    "id": f"{project_name}_SC_002",
                    "domain": "smart_contract",
                    "name": "Staking Pool",
                    "description": "Pool de staking avec r√©compenses",
                    "language": "solidity",
                    "version": "0.8.19",
                    "framework": "foundry",
                    "complexity": 4,
                    "depends_on": [f"{project_name}_SC_001"],
                    "specification": {
                        "contract_name": f"{project_name}Staking",
                        "features": ["stake", "unstake", "claim", "compound"]
                    }
                },
                {
                    "id": f"{project_name}_BE_001",
                    "domain": "backend",
                    "name": "API FastAPI",
                    "description": "API REST pour le projet",
                    "language": "python",
                    "version": "3.11",
                    "framework": "fastapi",
                    "complexity": 3,
                    "depends_on": [f"{project_name}_SC_001", f"{project_name}_DB_001"],
                    "specification": {
                        "endpoints": ["/balance", "/transfer", "/stake", "/rewards"],
                        "database": "postgresql",
                        "cache": "redis"
                    }
                },
                {
                    "id": f"{project_name}_FE_001",
                    "domain": "frontend",
                    "name": "Interface React",
                    "description": "Application React avec WalletConnect",
                    "language": "typescript",
                    "version": "5.0",
                    "framework": "nextjs",
                    "complexity": 3,
                    "depends_on": [f"{project_name}_BE_001"],
                    "specification": {
                        "pages": ["dashboard", "staking", "admin"],
                        "wallets": ["metamask", "walletconnect"]
                    }
                },
                {
                    "id": f"{project_name}_DB_001",
                    "domain": "database",
                    "name": "Sch√©ma PostgreSQL",
                    "description": "Base de donn√©es du projet",
                    "language": "sql",
                    "version": "15",
                    "framework": "alembic",
                    "complexity": 2,
                    "specification": {
                        "tables": ["users", "transactions", "staking_positions"]
                    }
                },
                {
                    "id": f"{project_name}_DO_001",
                    "domain": "devops",
                    "name": "Infrastructure Docker",
                    "description": "D√©ploiement conteneuris√©",
                    "language": "yaml",
                    "version": "docker-compose-v3",
                    "complexity": 3,
                    "depends_on": [f"{project_name}_BE_001", f"{project_name}_FE_001", f"{project_name}_DB_001"],
                    "specification": {
                        "services": ["postgres", "redis", "backend", "frontend", "nginx"],
                        "environments": ["development", "staging", "production"]
                    }
                },
                {
                    "id": f"{project_name}_DOC_001",
                    "domain": "documentation",
                    "name": "Documentation",
                    "description": "Documentation compl√®te",
                    "language": "markdown",
                    "framework": "mkdocs",
                    "complexity": 2,
                    "depends_on": ["*"],
                    "specification": {
                        "sections": ["introduction", "architecture", "api", "deployment", "user_guide"]
                    }
                }
            ],
            "dependencies": [
                {"from": f"{project_name}_SC_002", "to": f"{project_name}_SC_001"},
                {"from": f"{project_name}_BE_001", "to": f"{project_name}_SC_001"},
                {"from": f"{project_name}_BE_001", "to": f"{project_name}_DB_001"},
                {"from": f"{project_name}_FE_001", "to": f"{project_name}_BE_001"},
                {"from": f"{project_name}_DO_001", "to": f"{project_name}_BE_001"},
                {"from": f"{project_name}_DO_001", "to": f"{project_name}_FE_001"},
                {"from": f"{project_name}_DO_001", "to": f"{project_name}_DB_001"},
                {"from": f"{project_name}_DOC_001", "to": "*"}
            ]
        }

    def _get_nft_template(self, project_name: str) -> Dict:
        """Template pour projet NFT"""
        # Similaire mais adapt√© aux NFTs
        template = self._get_defi_template(project_name)
        template["type"] = "nft"
        template["description"] = "Collection NFT avec mint, marketplace et royalties"
        # Adapter les fragments pour NFT...
        return template

    def _get_gaming_template(self, project_name: str) -> Dict:
        """Template pour projet Gaming"""
        template = self._get_defi_template(project_name)
        template["type"] = "gaming"
        template["description"] = "Jeu Web3 avec tokens, items et marketplace"
        return template

    def _get_dao_template(self, project_name: str) -> Dict:
        """Template pour projet DAO"""
        template = self._get_defi_template(project_name)
        template["type"] = "dao"
        template["description"] = "DAO avec gouvernance, treasury et votes"
        return template
        
    # =================================================================
    # GESTION DES WORKFLOWS
    # =================================================================
    
    async def create_workflow(self, 
                             name: str,
                             steps: List[Dict[str, Any]] = None,
                             workflow_type: str = "standard") -> Workflow:
        """
        Cr√©e un nouveau workflow
        
        Args:
            name: Nom du workflow
            steps: Liste des √©tapes
            workflow_type: Type de workflow
            
        Returns:
            Workflow cr√©√©
        """
        self._logger.info(f"üìã Cr√©ation du workflow: {name}")
        
        workflow = Workflow(name, workflow_type)
        
        if steps:
            for step_config in steps:
                step = WorkflowStep(
                    name=step_config["name"],
                    agent_type=step_config["agent"],
                    task_type=step_config["task"],
                    parameters=step_config.get("parameters", {}),
                    depends_on=step_config.get("depends_on", [])
                )
                workflow.add_step(step)
        
        self._workflows[workflow.id] = workflow
        workflow.status = WorkflowStatus.READY
        
        self._logger.info(f"‚úÖ Workflow cr√©√©: {workflow.id} ({len(workflow.steps)} √©tapes)")
        return workflow
    
    async def execute_workflow(self, workflow_id: str) -> Dict[str, Any]:
        """
        Ex√©cute un workflow
        
        Args:
            workflow_id: ID du workflow
            
        Returns:
            R√©sultats du workflow
        """
        if workflow_id not in self._workflows:
            raise ValueError(f"Workflow {workflow_id} non trouv√©")
        
        workflow = self._workflows[workflow_id]
        workflow.status = WorkflowStatus.RUNNING
        workflow.started_at = datetime.now()
        
        self._logger.info(f"üöÄ Ex√©cution du workflow: {workflow.name} ({workflow_id})")
        self._stats["workflows_executed"] += 1
        
        try:
            # R√©soudre l'ordre d'ex√©cution
            execution_order = self._resolve_execution_order(workflow)
            self._logger.info(f"üìä Ordre d'ex√©cution: {[s.name for s in execution_order]}")
            
            # Ex√©cuter les √©tapes
            results = {}
            
            for step in execution_order:
                # V√©rifier les d√©pendances
                deps_satisfied = all(
                    results.get(dep, {}).get("success", False)
                    for dep in step.depends_on
                )
                
                if not deps_satisfied:
                    self._logger.error(f"‚ùå √âtape {step.name}: d√©pendances non satisfaites")
                    step.status = StepStatus.BLOCKED
                    workflow.status = WorkflowStatus.FAILED
                    break
                
                # Ex√©cuter l'√©tape
                result = await self._execute_step(step, workflow.context)
                results[step.name] = result
                self._stats["steps_executed"] += 1
                
                if not result.get("success", False):
                    self._stats["steps_failed"] += 1
                    if not self.config.get("continue_on_error", False):
                        workflow.status = WorkflowStatus.FAILED
                        break
            
            # Finaliser le workflow
            workflow.completed_at = datetime.now()
            
            if all(s.status == StepStatus.COMPLETED for s in workflow.steps):
                workflow.status = WorkflowStatus.COMPLETED
                self._stats["workflows_completed"] += 1
                self._logger.info(f"üéâ Workflow {workflow.name} termin√© avec succ√®s")
            else:
                workflow.status = WorkflowStatus.FAILED
                self._stats["workflows_failed"] += 1
                self._logger.warning(f"‚ö†Ô∏è Workflow {workflow.name} termin√© avec des √©checs")
            
            return {
                "workflow_id": workflow.id,
                "status": workflow.status.value,
                "steps_completed": sum(1 for s in workflow.steps if s.status == StepStatus.COMPLETED),
                "steps_failed": sum(1 for s in workflow.steps if s.status == StepStatus.FAILED),
                "duration_seconds": (workflow.completed_at - workflow.started_at).total_seconds(),
                "results": results
            }
            
        except Exception as e:
            self._logger.error(f"‚ùå Erreur workflow: {e}")
            workflow.status = WorkflowStatus.FAILED
            self._stats["workflows_failed"] += 1
            return {
                "workflow_id": workflow.id,
                "status": "failed",
                "error": str(e)
            }
    
    def _resolve_execution_order(self, workflow: Workflow) -> List[WorkflowStep]:
        """R√©sout l'ordre d'ex√©cution des √©tapes (tri topologique)"""
        # Construire le graphe des d√©pendances
        graph = {step.name: set(step.depends_on) for step in workflow.steps}
        
        # Tri topologique
        visited = set()
        order = []
        
        def dfs(node_name):
            visited.add(node_name)
            step = next(s for s in workflow.steps if s.name == node_name)
            
            for dep in step.depends_on:
                if dep not in visited:
                    dfs(dep)
            
            order.append(step)
        
        for step in workflow.steps:
            if step.name not in visited:
                dfs(step.name)
        
        return order
    
    async def _execute_step(self, step: WorkflowStep, context: Dict) -> Dict[str, Any]:
        """Ex√©cute une √©tape du workflow"""
        self._logger.info(f"‚öôÔ∏è Ex√©cution: {step.name} ({step.agent_type}.{step.task_type})")
        
        step.status = StepStatus.RUNNING
        step.started_at = datetime.now()
        
        try:
            # Simuler l'ex√©cution pour l'instant
            await asyncio.sleep(0.5)
            
            step.status = StepStatus.COMPLETED
            step.completed_at = datetime.now()
            
            return {
                "success": True,
                "step": step.name,
                "result": {"message": "√âtape ex√©cut√©e avec succ√®s"}
            }
            
        except Exception as e:
            step.status = StepStatus.FAILED
            step.error = str(e)
            step.completed_at = datetime.now()
            
            self._logger.error(f"‚ùå √âtape {step.name} √©chou√©e: {e}")
            
            return {
                "success": False,
                "step": step.name,
                "error": str(e)
            }
    
    

    # =================================================================
    # GESTION DES SPRINTS
    # =================================================================

    def _generate_sprint_report(self, specs: Dict, results: List[Dict], metrics: Dict) -> Dict:
        """
        G√©n√®re un rapport d√©taill√© du sprint
        
        Args:
            specs: Sp√©cifications originales
            results: R√©sultats des fragments
            metrics: M√©triques du sprint
        
        Returns:
            Rapport complet
        """
        # Compter les succ√®s par domaine
        by_domain = {}
        for result in results:
            domain = result.get("domain", "unknown")
            if domain not in by_domain:
                by_domain[domain] = {"total": 0, "success": 0, "failed": 0}
            
            by_domain[domain]["total"] += 1
            if result.get("success", False):
                by_domain[domain]["success"] += 1
            else:
                by_domain[domain]["failed"] += 1
        
        # Calculer les m√©triques globales
        total_fragments = len(results)
        successful = sum(1 for r in results if r.get("success", False))
        success_rate = (successful / total_fragments * 100) if total_fragments > 0 else 0
        
        # G√©n√©rer les recommandations
        recommendations = self._generate_recommendations(metrics, results)
        
        report = {
            "sprint": specs.get("sprint", "SPRINT-000"),
            "name": specs.get("name", "Sans nom"),
            "timestamp": datetime.now().isoformat(),
            "metrics": {
                "total_fragments": total_fragments,
                "successful": successful,
                "failed": total_fragments - successful,
                "success_rate": round(success_rate, 1),
                "by_domain": by_domain,
                **metrics
            },
            "results": results,
            "recommendations": recommendations
        }
        
        return report
    
    async def execute_sprint(self, spec_file: str) -> Dict[str, Any]:
        """
        Ex√©cute un sprint complet
        
        Args:
            spec_file: Chemin vers le fichier de sp√©cification
            
        Returns:
            Rapport d√©taill√© du sprint
        """
        self._logger.info(f"üöÄ D√©marrage du sprint avec sp√©cifications: {spec_file}")
        
        # V√©rifier que le sprint manager est initialis√©
        if not self._sprint_manager:
            self._sprint_manager = SprintManager(self.config.get("sprint_config", {}))
            self._sprint_manager.set_logger(self._logger.info)
        
        # Charger les sp√©cifications
        specs = self._sprint_manager.load_specs(spec_file)
        
        # Planifier le sprint
        fragments = self._sprint_manager.plan_sprint()
        self._logger.info(f"üìã Planification: {len(fragments)} fragments √† ex√©cuter")
        
        # Ex√©cuter chaque fragment
        results = []
        for fragment in fragments:
            result = await self._execute_fragment(fragment)
            results.append(result)
            
            # Mettre √† jour les m√©triques
            if result.get("success"):
                self._sprint_manager.metrics["fragments_completed"] += 1
            else:
                self._sprint_manager.metrics["fragments_failed"] += 1
        
        # Calculer les m√©triques finales
        total = self._sprint_manager.metrics["fragments_total"]
        completed = self._sprint_manager.metrics["fragments_completed"]
        self._sprint_manager.metrics["success_rate"] = (completed / total * 100) if total > 0 else 0
        self._sprint_manager.metrics["sprints_completed"] += 1
        self._stats["sprints_completed"] += 1
        
        # G√©n√©rer le rapport
        report = self._generate_sprint_report(specs, results, self._sprint_manager.metrics)
        
        # Sauvegarder les artefacts
        await self._save_sprint_artifacts(specs, results, report)
        
        return report
    
    async def _execute_fragment(self, fragment: Dict) -> Dict[str, Any]:
        """
        Ex√©cute un fragment unique avec probabilit√© de succ√®s adaptative
        
        Args:
            fragment: Sp√©cification du fragment √† ex√©cuter
            
        Returns:
            R√©sultat de l'ex√©cution avec m√©tadonn√©es
        """
        fragment_id = fragment["id"]
        domain = fragment.get("domain", "unknown")
        language = fragment.get("language", "unknown")
        complexity = fragment.get("complexity", 3)
        name = fragment.get("name", "")
        
        self._logger.info(f"üì¶ [{domain}] Fragment {fragment_id} ({language}) - {name}")
        self._logger.info(f"   üìä Complexit√©: {complexity}")
        
        # Simulation d'ex√©cution avec d√©lai bas√© sur la complexit√©
        execution_time = 0.2 * complexity
        await asyncio.sleep(execution_time)
        
        import random
        
        # =================================================================
        # CALCUL DU TAUX DE SUCC√àS DE BASE
        # =================================================================
        
        # Base rate selon la complexit√©
        if complexity <= 2:
            base_rate = 0.95  # 95% pour les fragments simples
        elif complexity <= 3:
            base_rate = 0.85  # 85% pour les fragments moyens
        elif complexity <= 4:
            base_rate = 0.75  # 75% pour les fragments complexes
        else:
            base_rate = 0.60  # 60% pour les fragments tr√®s complexes
        
        success_rate = base_rate
        bonuses = []
        
        # =================================================================
        # BONUS SELON LE DOMAINE
        # =================================================================
        
        # Bonus pour le frontend (souvent plus difficile)
        if domain == "frontend":
            success_rate += 0.10  # +10% pour le frontend
            bonuses.append("frontend_bonus")
            self._logger.info(f"   üé® Bonus frontend appliqu√©: +10%")
        
        # Bonus pour la documentation (souvent plus simple)
        if domain == "documentation":
            success_rate += 0.15  # +15% pour la doc
            bonuses.append("doc_bonus")
        
        # Bonus pour le backend (bien standardis√©)
        if domain == "backend":
            success_rate += 0.05  # +5% pour le backend
            bonuses.append("backend_bonus")
        
        # =================================================================
        # BONUS POUR LES D√âPENDANCES SATISFAITES
        # =================================================================
        
        # V√©rifier si les d√©pendances existent et ont r√©ussi
        depends_on = fragment.get("depends_on", [])
        if depends_on and hasattr(self, '_sprint_manager') and self._sprint_manager:
            deps_satisfied = True
            for dep_id in depends_on:
                if dep_id == "*":  # D√©pend de tous
                    continue
                if dep_id in self._sprint_manager.results:
                    if not self._sprint_manager.results[dep_id].get("success", False):
                        deps_satisfied = False
                        self._logger.info(f"   ‚ö†Ô∏è D√©pendance non satisfaite: {dep_id}")
                else:
                    deps_satisfied = False
                    self._logger.info(f"   ‚ö†Ô∏è D√©pendance manquante: {dep_id}")
            
            if deps_satisfied:
                success_rate += 0.10  # +10% si toutes les d√©pendances sont OK
                bonuses.append("dependencies_ok")
                self._logger.info(f"   üîó Bonus d√©pendances: +10%")
        
        # =================================================================
        # BONUS SP√âCIFIQUE POUR STAKING POOL
        # =================================================================
        
        if "Staking" in name or "SC_002" in fragment_id:
            self._logger.info(f"   ‚öôÔ∏è Application de r√®gles sp√©ciales pour StakingPool")
            
            # V√©rifier que le token de base existe (SC_001)
            token_fragment_id = fragment_id.replace("SC_002", "SC_001")
            
            if hasattr(self, '_sprint_manager') and self._sprint_manager:
                results = self._sprint_manager.results
                if token_fragment_id in results and results[token_fragment_id].get("success", False):
                    success_rate += 0.15  # +15% de bonus
                    bonuses.append("staking_bonus")
                    self._logger.info(f"   ‚úÖ D√©pendance {token_fragment_id} valid√©e, bonus +15% appliqu√©")
        
        # =================================================================
        # BONUS POUR LES FRAGMENTS AVEC TESTS D√âTAILL√âS
        # =================================================================
        
        if "tests" in fragment and len(fragment.get("tests", {}).get("unit", [])) > 5:
            success_rate += 0.05  # +5% si beaucoup de tests
            bonuses.append("good_test_coverage")
        
        # =================================================================
        # MALUS POUR LES FRAGMENTS TR√àS COMPLEXES
        # =================================================================
        
        if complexity >= 4 and "staking" in name.lower():
            success_rate -= 0.10  # -10% pour staking complexe
            self._logger.info(f"   ‚ö†Ô∏è Malus complexit√© staking: -10%")
        
        # Limiter le taux entre 0.5 et 0.98
        success_rate = max(0.5, min(0.98, success_rate))
        
        # =================================================================
        # EX√âCUTION SIMUL√âE
        # =================================================================
        
        success = random.random() < success_rate
        
        # Nombre d'it√©rations simul√©
        if success:
            iterations = random.randint(1, 3)
            if complexity >= 4:
                iterations += random.randint(0, 1)  # Une it√©ration de plus pour les complexes
        else:
            iterations = random.randint(3, 5)
            if bonuses:
                iterations -= 1  # Moins d'it√©rations si on avait des bonus
        
        iterations = max(1, iterations)
        
        # =================================================================
        # PR√âPARATION DU R√âSULTAT
        # =================================================================
        
        result = {
            "fragment_id": fragment_id,
            "domain": domain,
            "name": name,
            "complexity": complexity,
            "success": success,
            "iterations": iterations,
            "success_rate": round(success_rate * 100, 1),
            "bonuses": bonuses,
            "timestamp": datetime.now().isoformat()
        }
        
        # Ajouter des raisons d'√©chec si n√©cessaire
        if not success:
            reasons = []
            if complexity > 3:
                reasons.append("Complexit√© √©lev√©e")
            if "staking" in name.lower():
                reasons.append("Logique de r√©compense complexe")
            if random.random() < 0.3:
                reasons.append("Probl√®me de gas estimation")
            if domain == "frontend":
                reasons.append("Compatibilit√© navigateur")
                reasons.append("Int√©gration WalletConnect")
            
            result["failure_reasons"] = reasons
            self._logger.info(f"   üìã Raisons: {', '.join(reasons)}")
        
        # =================================================================
        # LOGGING DU R√âSULTAT
        # =================================================================
        
        if success:
            self._logger.info(f"   ‚úÖ Fragment {fragment_id} valid√©")
            self._logger.info(f"      üìà Taux: {success_rate:.0%} | It√©rations: {iterations} | Bonus: {len(bonuses)}")
        else:
            self._logger.warning(f"   ‚ùå Fragment {fragment_id} √©chou√©")
            self._logger.info(f"      üìâ Taux: {success_rate:.0%} | It√©rations: {iterations}")
        
        return result
    
    def _generate_recommendations(self, metrics: Dict, results: List[Dict]) -> List[str]:
        """
        G√©n√®re des recommandations pour le prochain sprint
        
        Args:
            metrics: M√©triques du sprint
            results: R√©sultats des fragments
        
        Returns:
            Liste de recommandations
        """
        recommendations = []
        
        # Analyser les taux d'√©chec par domaine
        by_domain = {}
        for result in results:
            domain = result.get("domain", "unknown")
            if domain not in by_domain:
                by_domain[domain] = {"total": 0, "failed": 0}
            
            by_domain[domain]["total"] += 1
            if not result.get("success", False):
                by_domain[domain]["failed"] += 1
        
        for domain, stats in by_domain.items():
            if stats["total"] > 0 and stats["failed"] > 0:
                fail_rate = stats["failed"] / stats["total"] * 100
                if fail_rate > 30:
                    recommendations.append(
                        f"‚ö†Ô∏è Domaine '{domain}': taux d'√©chec √©lev√© ({fail_rate:.1f}%). "
                        "Revoir les sp√©cifications."
                    )
        
        # Recommandations globales
        success_rate = metrics.get("success_rate", 0)
        if success_rate < 70:
            recommendations.append(
                f"üéØ Taux de succ√®s global faible ({success_rate:.1f}%). "
                "Envisager une phase de conception plus approfondie."
            )
        
        # Fragments lents
        slow_fragments = [r for r in results if r.get("iterations", 0) > 3]
        if slow_fragments:
            recommendations.append(
                f"üê¢ {len(slow_fragments)} fragments ont n√©cessit√© plus de 3 it√©rations. "
                "Les d√©tailler davantage."
            )
        
        # Recommandations sp√©cifiques
        failed_fragments = [r for r in results if not r.get("success", False)]
        if failed_fragments:
            failed_ids = [r["fragment_id"] for r in failed_fragments[:3]]
            recommendations.append(
                f"üîç Analyser les √©checs: {', '.join(failed_ids)}"
            )
        
        return recommendations
    
    async def _save_sprint_artifacts(self, specs: Dict, results: List[Dict], report: Dict):
        """Sauvegarde les artefacts du sprint"""
        sprint_id = specs.get("sprint", "SPRINT-000")
        base_path = Path(self.config.get("sprint_config", {}).get("reports_path", "./reports/sprints/"))
        base_path.mkdir(parents=True, exist_ok=True)
        
        # Rapport JSON
        report_file = base_path / f"{sprint_id}_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self._logger.info(f"üíæ Rapport sauvegard√©: {report_file}")
    
    # =================================================================
    # UTILITAIRES
    # =================================================================
    
    async def get_workflow_status(self, workflow_id: str) -> Optional[Dict]:
        """Retourne le statut d'un workflow"""
        if workflow_id not in self._workflows:
            return None
        return self._workflows[workflow_id].to_dict()
    
    async def list_workflows(self, status: Optional[str] = None) -> List[Dict]:
        """Liste tous les workflows"""
        workflows = []
        for workflow in self._workflows.values():
            if status and workflow.status.value != status:
                continue
            workflows.append(workflow.to_dict())
        return workflows
    
    async def get_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques"""
        return {
            **self._stats,
            "uptime_seconds": (datetime.now() - self._stats["start_time"]).total_seconds(),
            "active_workflows": len([w for w in self._workflows.values() if w.status == WorkflowStatus.RUNNING])
        }
    
    # =================================================================
    # REQUIS PAR BASEAGENT
    # =================================================================
    
    async def health_check(self) -> Dict[str, Any]:
        """V√©rifie la sant√© de l'agent"""
        stats = await self.get_statistics()
        
        return {
            "agent": self._name,
            "status": self._status.value if hasattr(self._status, 'value') else str(self._status),
            "ready": self._status == AgentStatus.READY,
            "workflows_executed": stats["workflows_executed"],
            "sprints_completed": stats["sprints_completed"],
            "components": list(self._components.keys()),
            "uptime": stats["uptime_seconds"]
        }
    
    def get_agent_info(self) -> Dict[str, Any]:
        """Informations de l'agent"""
        return {
            "id": self._name,
            "name": "üöÄ Orchestrator Agent",
            "version": "2.0.0",
            "description": "Orchestration des workflows et sprints",
            "status": self._status.value if hasattr(self._status, 'value') else str(self._status),
            "capabilities": [
                "workflow_orchestration",
                "sprint_management",
                "multi_domain_planning",
                "fragment_execution",
                "report_generation"
            ],
            "workflows_created": len(self._workflows),
            "sprints_completed": self._stats["sprints_completed"]
        }
    
    async def _handle_custom_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Gestion des messages personnalis√©s"""
        msg_type = message.get("type", "")
        
        if msg_type == "create_workflow":
            workflow = await self.create_workflow(
                name=message.get("name", "Workflow"),
                steps=message.get("steps"),
                workflow_type=message.get("type", "standard")
            )
            return {"workflow_id": workflow.id, "status": "created"}
        
        elif msg_type == "execute_workflow":
            result = await self.execute_workflow(message["workflow_id"])
            return result
        
        elif msg_type == "execute_sprint":
            report = await self.execute_sprint(message["spec_file"])
            return report
        
        elif msg_type == "list_workflows":
            workflows = await self.list_workflows(message.get("status"))
            return {"workflows": workflows}
        
        elif msg_type == "workflow_status":
            status = await self.get_workflow_status(message["workflow_id"])
            return status or {"error": "Workflow not found"}
        
        elif msg_type == "statistics":
            return await self.get_statistics()
        
        return {"status": "received", "type": msg_type}


# =====================================================================
# FONCTIONS D'USINE
# =====================================================================

def create_orchestrator_agent(config_path: str = "") -> OrchestratorAgent:
    """Cr√©e une instance de l'orchestrateur"""
    return OrchestratorAgent(config_path)


# =====================================================================
# POINT D'ENTR√âE POUR EX√âCUTION DIRECTE
# =====================================================================

if __name__ == "__main__":
    async def main():
        print("üöÄ TEST ORCHESTRATOR AGENT")
        print("="*60)
        
        agent = OrchestratorAgent()
        await agent.initialize()
        
        print(f"‚úÖ Agent: {agent.get_agent_info()['name']}")
        print(f"‚úÖ Statut: {agent._status.value if hasattr(agent._status, 'value') else agent._status}")
        print(f"‚úÖ Composants: {list(agent._components.keys())}")
        
        # Test cr√©ation workflow
        workflow = await agent.create_workflow(
            name="Test Workflow",
            steps=[
                {
                    "name": "step1",
                    "agent": "test_agent",
                    "task": "test_task",
                    "parameters": {"param": "value"}
                }
            ]
        )
        print(f"\nüìã Workflow cr√©√©: {workflow.id}")
        
        # Test ex√©cution
        result = await agent.execute_workflow(workflow.id)
        print(f"üöÄ Ex√©cution: {result['status']}")
        
        # Test sprint
        print(f"\nüì¶ Test sprint manager...")
        report = await agent.execute_sprint("specs/defi_app.json")
        print(f"‚úÖ Sprint {report['sprint']} termin√©")
        print(f"üìä Taux de succ√®s: {report['metrics']['success_rate']:.1f}%")
        
        print("\n" + "="*60)
        print("‚úÖ ORCHESTRATOR AGENT OP√âRATIONNEL")
        print("="*60)
    
    asyncio.run(main())